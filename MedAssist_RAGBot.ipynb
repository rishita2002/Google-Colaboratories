{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishita2002/Google-Colaboratories/blob/main/MedAssist_RAGBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Disclaimer:**\n",
        "This notebook utilizes a retrieval-augmented generation (RAG) model combined with a large language model (LLM), which may produce results that are not factual or accurate. We do not assume ownership or responsibility for the accuracy or reliability of these outputs."
      ],
      "metadata": {
        "id": "wSNgOAJ-wWdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MedAssist RAGBot\n",
        "\n",
        "Using the RAG methodology, MedAssist RAGbot transforms healthcare information by providing immediate, tailored access. By providing customers with clear and concise medical explanations, it guarantees effective and comprehensible health insights.\n"
      ],
      "metadata": {
        "id": "ogsDKhF18SkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RAG Approach to import external knowledge into LLM as context\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) is a method that uses a combination of pre-defined rules or parameters (non-parametric memory) and external information from the internet (parametric memory) to generate responses to questions or create new ones."
      ],
      "metadata": {
        "id": "0iiGvMYZuwvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monster API LLM Integration into LLamaIndex\n",
        "MonsterAPI Hosts wide range of popular LLMs as inference service and this notebook serves as a tutorial about how to use llama-index to access MonsterAPI LLMs.\n",
        "\n",
        "Check us out here: https://monsterapi.ai/"
      ],
      "metadata": {
        "id": "De2IjZwh8hEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libraries"
      ],
      "metadata": {
        "id": "Snd4DJpSsl2W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N68KG83NnHat"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install llama-index\n",
        "!python3 -m pip install monsterapi\n",
        "!python3 -m pip install sentence_transformers\n",
        "!python3 -m pip install pypdf #this modeule is required for pdf parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required modules"
      ],
      "metadata": {
        "id": "9zxq3pBEstwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGGzMR8snHau"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from llama_index.llms import MonsterLLM\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set Monster API Key env variable\n",
        "Sign up on MonsterAPI and get a free auth key :\n",
        "https://monsterapi.ai/signup\n",
        "\n",
        "Paste it below:"
      ],
      "metadata": {
        "id": "0u7TZb5msyCw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsXgrJFKnHav"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MONSTER_API_KEY\"] = \"YOUR MONSTERAPI KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic Usage Pattern\n",
        "Step 1: Set the model\n",
        "\n",
        "Step 2: Initiate LLM and Embedding Model\n",
        "\n",
        "Step 3: Load the document\n",
        "\n",
        "Step 4: Create embedding store and create index\n",
        "\n",
        "Step 5: LLM Output with RAG"
      ],
      "metadata": {
        "id": "8QItX_-jt3lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1\n",
        "model = \"zephyr-7b-beta\""
      ],
      "metadata": {
        "id": "7vKHIhMGuiMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5bODEApnHaw"
      },
      "outputs": [],
      "source": [
        "#Step 2\n",
        "llm = MonsterLLM(model=model, temperature=0.75, context_window=1024)\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024, llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3\n",
        "!rm -r ./data\n",
        "!mkdir -p data&&cd data&&curl 'https://bookspz.b-cdn.net/UMLE%20STEP%201%20CLOUD/First%20Aid%20for%20the%20USMLE%20Step%201-2019.pdf' -o \"health.pdf\"\n",
        "documents = SimpleDirectoryReader(\"./data\").load_data()"
      ],
      "metadata": {
        "id": "S7EZE5plaXk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54-rUF4vnHa0"
      },
      "outputs": [],
      "source": [
        "#Step 4\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, service_context=service_context\n",
        ")\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh2pc6CNnHa0"
      },
      "outputs": [],
      "source": [
        "#Step 5\n",
        "response = query_engine.query(\"what is cancer and its treatments\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}